#!/usr/bin/env python3
"""
Database seeding script from CSV files in output/csv_export.

This script reads the normalized CSV files and reconstructs full Pattern objects
for insertion into the database.
"""

import sys
import csv
from pathlib import Path
from collections import defaultdict
from typing import Dict, List, Optional

from database import init_db, drop_db, SessionLocal, PatternRepository
from models import (
    Pattern, Metadata, Definition, MathExpression, Components, Component,
    Properties, Property, Operations, Operation, TypeDefinitions, TypeDef,
    Dependencies, PatternRefs, Manifestations, Manifestation, Domains,
    Invariants, Conditions, Effects
)


def read_csv_file(filepath: Path) -> List[Dict[str, str]]:
    """Read a CSV file and return list of dictionaries."""
    with open(filepath, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        return list(reader)


def build_patterns_from_csv(csv_dir: Path) -> Dict[str, Pattern]:
    """
    Build Pattern objects from CSV files.
    
    Args:
        csv_dir: Directory containing CSV files
        
    Returns:
        Dictionary mapping pattern_id to Pattern object
    """
    print("\nüìÇ Reading CSV files...")
    
    # Read all CSV files
    patterns_summary = read_csv_file(csv_dir / 'patterns_summary.csv')
    components_data = read_csv_file(csv_dir / 'components.csv')
    properties_data = read_csv_file(csv_dir / 'properties.csv')
    operations_data = read_csv_file(csv_dir / 'operations.csv')
    type_defs_data = read_csv_file(csv_dir / 'type_definitions.csv')
    dependencies_data = read_csv_file(csv_dir / 'dependencies.csv')
    manifestations_data = read_csv_file(csv_dir / 'manifestations.csv')
    
    # Optional: property invariants and operation conditions
    property_invariants_file = csv_dir / 'property_invariants.csv'
    operation_conditions_file = csv_dir / 'operation_conditions.csv'
    
    property_invariants_data = read_csv_file(property_invariants_file) if property_invariants_file.exists() else []
    operation_conditions_data = read_csv_file(operation_conditions_file) if operation_conditions_file.exists() else []
    
    print(f"  ‚úì Patterns: {len(patterns_summary)}")
    print(f"  ‚úì Components: {len(components_data)}")
    print(f"  ‚úì Properties: {len(properties_data)}")
    print(f"  ‚úì Operations: {len(operations_data)}")
    print(f"  ‚úì Type Definitions: {len(type_defs_data)}")
    print(f"  ‚úì Dependencies: {len(dependencies_data)}")
    print(f"  ‚úì Manifestations: {len(manifestations_data)}")
    if property_invariants_data:
        print(f"  ‚úì Property Invariants: {len(property_invariants_data)}")
    if operation_conditions_data:
        print(f"  ‚úì Operation Conditions: {len(operation_conditions_data)}")
    
    # Group related data by pattern_id
    components_by_pattern = defaultdict(list)
    for comp in components_data:
        pid = comp['pattern_id']
        if pid:  # Skip empty pattern_ids
            components_by_pattern[pid].append(comp)
    
    properties_by_pattern = defaultdict(list)
    for prop in properties_data:
        pid = prop['pattern_id']
        if pid:  # Skip empty pattern_ids
            properties_by_pattern[pid].append(prop)
    
    operations_by_pattern = defaultdict(list)
    for op in operations_data:
        pid = op['pattern_id']
        if pid:  # Skip empty pattern_ids
            operations_by_pattern[pid].append(op)
    
    type_defs_by_pattern = defaultdict(list)
    for td in type_defs_data:
        pid = td['pattern_id']
        if pid:
            type_defs_by_pattern[pid].append(td)
    
    # Group dependencies by source pattern
    dependencies_by_pattern = defaultdict(lambda: {'requires': [], 'uses': [], 'specializes': [], 'specialized_by': []})
    for dep in dependencies_data:
        source_id = dep['source_id']
        target_id = dep['target_id']
        rel_type = dep['relationship_type']
        if source_id and target_id and rel_type:
            if rel_type == 'requires':
                dependencies_by_pattern[source_id]['requires'].append(target_id)
            elif rel_type == 'uses':
                dependencies_by_pattern[source_id]['uses'].append(target_id)
            elif rel_type == 'specializes':
                dependencies_by_pattern[source_id]['specializes'].append(target_id)
            # Also track specialized_by in reverse
            if rel_type == 'specializes':
                dependencies_by_pattern[target_id]['specialized_by'].append(source_id)
    
    manifestations_by_pattern = defaultdict(list)
    for manif in manifestations_data:
        pid = manif['pattern_id']
        if pid:
            manifestations_by_pattern[pid].append(manif)
    
    property_invariants_by_property = defaultdict(list)
    for inv in property_invariants_data:
        prop_id = inv.get('property_id', '')
        if prop_id:
            property_invariants_by_property[prop_id].append(inv)
    
    operation_conditions_by_operation = defaultdict(lambda: {'preconditions': [], 'postconditions': []})
    for cond in operation_conditions_data:
        op_key = f"{cond.get('pattern_id', '')}:{cond.get('operation_name', '')}"
        cond_type = cond.get('condition_type', '')
        if cond_type == 'precondition':
            operation_conditions_by_operation[op_key]['preconditions'].append(cond)
        elif cond_type == 'postcondition':
            operation_conditions_by_operation[op_key]['postconditions'].append(cond)
    
    # Build Pattern objects
    patterns = {}
    skipped = 0
    
    print("\nüî® Building patterns...")
    
    for row in patterns_summary:
        pattern_id = row['id']
        
        # Skip rows with empty ID
        if not pattern_id:
            skipped += 1
            continue
        
        try:
            # Parse domains from CSV (semicolon-separated)
            domains_obj = None
            domains_str = row.get('domains', '').strip()
            if domains_str:
                domain_list = [d.strip() for d in domains_str.split(';') if d.strip()]
                if domain_list:
                    domains_obj = Domains(domain=domain_list)
            
            # Build metadata
            metadata = Metadata(
                name=row['name'] or f"Pattern {pattern_id}",
                category=row['category'] or 'pattern',
                status=row['status'] or 'draft',
                complexity=row['complexity'] if row['complexity'] else None,
                domains=domains_obj,
                last_updated=None  # Could be added to CSV later
            )
            
            # Build components
            comp_list = []
            for comp_row in components_by_pattern.get(pattern_id, []):
                comp_list.append(Component(
                    name=comp_row['component_name'],
                    type=comp_row['component_type'],
                    notation=comp_row['notation'] if comp_row['notation'] else None,
                    description=comp_row['description']
                ))
            
            # If no components, add a placeholder
            if not comp_list:
                comp_list.append(Component(
                    name="component",
                    type="Type",
                    description="Pattern component"
                ))
            
            components = Components(component=comp_list)
            
            # Build definition
            definition = Definition(
                tuple_notation=MathExpression(
                    content=row['tuple_notation'] or f"${pattern_id}$",
                    format='latex'
                ),
                components=components
            )
            
            # Build properties (with invariants)
            prop_list = []
            for prop_row in properties_by_pattern.get(pattern_id, []):
                prop_id = prop_row['property_id']
                
                # Build invariants for this property
                invariants_obj = None
                inv_list = property_invariants_by_property.get(prop_id, [])
                if inv_list:
                    inv_exprs = [
                        MathExpression(
                            content=inv.get('invariant_expression', ''),
                            format='latex'
                        ) for inv in inv_list
                    ]
                    if inv_exprs:
                        invariants_obj = Invariants(invariant=inv_exprs)
                
                prop_list.append(Property(
                    id=prop_id,
                    name=prop_row['property_name'],
                    formal_spec=MathExpression(
                        content=prop_row['formal_spec'],
                        format='latex'
                    ),
                    description=prop_row.get('description') if prop_row.get('description') else None,
                    invariants=invariants_obj
                ))
            
            # If no properties, add a placeholder
            if not prop_list:
                prop_list.append(Property(
                    id=f"P.{pattern_id}.1",
                    name="Core Property",
                    formal_spec=MathExpression(
                        content=f"Property of {pattern_id}",
                        format="latex"
                    )
                ))
            
            properties = Properties(property=prop_list)
            
            # Build operations (with conditions)
            op_list = []
            for op_row in operations_by_pattern.get(pattern_id, []):
                op_name = op_row['operation_name']
                op_key = f"{pattern_id}:{op_name}"
                
                # Build preconditions and postconditions
                preconditions_obj = None
                postconditions_obj = None
                
                cond_data = operation_conditions_by_operation.get(op_key, {})
                
                if cond_data.get('preconditions'):
                    pre_exprs = [
                        MathExpression(
                            content=c.get('condition_expression', ''),
                            format='latex'
                        ) for c in cond_data['preconditions']
                    ]
                    if pre_exprs:
                        preconditions_obj = Conditions(condition=pre_exprs)
                
                if cond_data.get('postconditions'):
                    post_exprs = [
                        MathExpression(
                            content=c.get('condition_expression', ''),
                            format='latex'
                        ) for c in cond_data['postconditions']
                    ]
                    if post_exprs:
                        postconditions_obj = Conditions(condition=post_exprs)
                
                op_list.append(Operation(
                    name=op_name,
                    signature=op_row['signature'],
                    formal_definition=MathExpression(
                        content=op_row['formal_definition'],
                        format='latex'
                    ),
                    preconditions=preconditions_obj,
                    postconditions=postconditions_obj
                ))
            
            # If no operations, add a placeholder
            if not op_list:
                op_list.append(Operation(
                    name="Execute",
                    signature=f"execute() ‚Üí Effect",
                    formal_definition=MathExpression(
                        content=f"Execute {pattern_id} operation",
                        format="latex"
                    )
                ))
            
            operations = Operations(operation=op_list)
            
            # Build type definitions
            type_defs_obj = None
            type_def_list = []
            for td_row in type_defs_by_pattern.get(pattern_id, []):
                type_def_list.append(TypeDef(
                    name=td_row['type_name'],
                    definition=MathExpression(
                        content=td_row['definition'],
                        format='latex'
                    )
                ))
            if type_def_list:
                type_defs_obj = TypeDefinitions(type_def=type_def_list)
            
            # Build dependencies
            deps_obj = None
            dep_data = dependencies_by_pattern.get(pattern_id, {})
            
            requires_obj = None
            if dep_data.get('requires'):
                requires_obj = PatternRefs(pattern_ref=dep_data['requires'])
            
            uses_obj = None
            if dep_data.get('uses'):
                uses_obj = PatternRefs(pattern_ref=dep_data['uses'])
            
            specializes_obj = None
            if dep_data.get('specializes'):
                specializes_obj = PatternRefs(pattern_ref=dep_data['specializes'])
            
            specialized_by_obj = None
            if dep_data.get('specialized_by'):
                specialized_by_obj = PatternRefs(pattern_ref=dep_data['specialized_by'])
            
            if requires_obj or uses_obj or specializes_obj or specialized_by_obj:
                deps_obj = Dependencies(
                    requires=requires_obj,
                    uses=uses_obj,
                    specializes=specializes_obj,
                    specialized_by=specialized_by_obj
                )
            
            # Build manifestations
            manifestations_obj = None
            manif_list = []
            for manif_row in manifestations_by_pattern.get(pattern_id, []):
                manif_list.append(Manifestation(
                    name=manif_row['manifestation_name'],
                    description=manif_row.get('description', '')
                ))
            if manif_list:
                manifestations_obj = Manifestations(manifestation=manif_list)
            
            # Create Pattern
            pattern = Pattern(
                id=pattern_id,
                version=row['version'] or '1.0',
                metadata=metadata,
                definition=definition,
                type_definitions=type_defs_obj,
                properties=properties,
                operations=operations,
                dependencies=deps_obj,
                manifestations=manifestations_obj
            )
            
            patterns[pattern_id] = pattern
            
        except Exception as e:
            print(f"  ‚úó Error building {pattern_id}: {e}")
            skipped += 1
            continue
    
    print(f"  ‚úì Built {len(patterns)} patterns")
    if skipped > 0:
        print(f"  ‚äò Skipped {skipped} invalid rows")
    
    return patterns


def seed_database(
    csv_dir: Path,
    skip_existing: bool = True,
    verbose: bool = True
) -> tuple[int, int, int]:
    """
    Seed the database from CSV files.
    
    Args:
        csv_dir: Directory containing CSV files
        skip_existing: Skip patterns that already exist in DB
        verbose: Print detailed progress
        
    Returns:
        Tuple of (loaded, skipped, failed) counts
    """
    # Build patterns from CSV
    patterns = build_patterns_from_csv(csv_dir)
    
    if not patterns:
        print("‚úó No patterns to load")
        return (0, 0, 0)
    
    print(f"\nüíæ Loading into database...")
    print("=" * 60)
    
    db = SessionLocal()
    repo = PatternRepository(db)
    
    loaded = 0
    skipped = 0
    failed = 0
    
    for pattern_id, pattern in sorted(patterns.items()):
        try:
            # Check if exists
            if skip_existing:
                existing = repo.get_by_id(pattern.id)
                if existing:
                    if verbose:
                        print(f"‚äò {pattern.id:8} - {pattern.metadata.name[:45]:45} (exists)")
                    skipped += 1
                    continue
            
            # Insert into database
            repo.create(pattern)
            loaded += 1
            
            if verbose:
                print(f"‚úì {pattern.id:8} - {pattern.metadata.name[:45]:45} ({pattern.metadata.category})")
        
        except Exception as e:
            failed += 1
            print(f"‚úó {pattern_id}: {str(e)[:60]}")
    
    db.close()
    
    return (loaded, skipped, failed)


def main():
    """Main seeding function."""
    print("=" * 60)
    print("Universal Corpus Pattern Database Seeding (from CSV)")
    print("=" * 60)
    
    # Parse arguments
    reset = '--reset' in sys.argv or '-r' in sys.argv
    quiet = '--quiet' in sys.argv or '-q' in sys.argv
    force = '--force' in sys.argv or '-f' in sys.argv
    
    # Determine CSV directory
    csv_dir = Path(__file__).parent / 'output' / 'csv_master'
    
    if not csv_dir.exists():
        print(f"‚úó Directory not found: {csv_dir}")
        sys.exit(1)
    
    # Check required files
    required_files = [
        'patterns_summary.csv', 
        'components.csv', 
        'properties.csv', 
        'operations.csv',
        'type_definitions.csv',
        'dependencies.csv',
        'manifestations.csv'
    ]
    missing = [f for f in required_files if not (csv_dir / f).exists()]
    
    if missing:
        print(f"‚úó Missing required CSV files: {', '.join(missing)}")
        sys.exit(1)
    
    # Optional files
    optional_files = ['property_invariants.csv', 'operation_conditions.csv']
    present_optional = [f for f in optional_files if (csv_dir / f).exists()]
    if present_optional:
        print(f"  ‚ÑπÔ∏è  Optional files present: {', '.join(present_optional)}")
    
    # Reset if requested
    if reset:
        print("\n‚ö†Ô∏è  Reset requested - all data will be lost!")
        if not force:
            response = input("Are you sure? (yes/no): ")
            if response.lower() != 'yes':
                print("Aborted.")
                return
        
        print("üóëÔ∏è  Dropping database...")
        drop_db()
        print("‚úì Database dropped")
    
    # Initialize database
    print("\nüì¶ Initializing database...")
    init_db()
    print("‚úì Database ready")
    
    # Seed database
    loaded, skipped, failed = seed_database(
        csv_dir=csv_dir,
        skip_existing=not reset,
        verbose=not quiet
    )
    
    # Summary
    print("\n" + "=" * 60)
    print("‚úÖ Seeding complete!")
    print("=" * 60)
    print(f"  Loaded:  {loaded:3} patterns")
    print(f"  Skipped: {skipped:3} patterns (already exist)")
    print(f"  Failed:  {failed:3} patterns")
    print(f"  Total:   {loaded + skipped:3} patterns in database")
    print("=" * 60)
    
    if failed > 0:
        print(f"\n‚ö†Ô∏è  {failed} patterns failed to load. Check errors above.")
    
    print("\nNext steps:")
    print("  1. Start API: python api.py")
    print("  2. View docs: http://localhost:8000/docs")
    print("  3. List patterns: curl http://localhost:8000/patterns")


if __name__ == '__main__':
    if '--help' in sys.argv or '-h' in sys.argv:
        print("Usage: python seed_from_csv.py [OPTIONS]")
        print("\nOptions:")
        print("  --reset, -r   Reset database before seeding")
        print("  --force, -f   Skip confirmation prompt")
        print("  --quiet, -q   Minimal output")
        print("  --help, -h    Show this help message")
        print("\nData source: output/csv_master/*.csv")
        print("\nExamples:")
        print("  python seed_from_csv.py              # Seed with existing data")
        print("  python seed_from_csv.py --reset      # Reset and seed")
        print("  python seed_from_csv.py -r -f -q     # Reset, force, quiet")
    else:
        main()

