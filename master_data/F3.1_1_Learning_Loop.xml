<?xml version='1.0' encoding='utf-8'?>
<ns0:pattern xmlns:ns0="http://universal-corpus.org/schema/v1" id="F3.1" version="1.1">
  <ns0:metadata>
    <ns0:name />
    <ns0:category>pattern</ns0:category>
    <ns0:status>stable</ns0:status>
    <ns0:complexity>medium</ns0:complexity>
  </ns0:metadata>
  <ns0:definition>
    <ns0:tuple-notation format="latex">$L = (observe, learn, update, apply)$</ns0:tuple-notation>
    <ns0:components>
      <ns0:component>
        <ns0:name>observe</ns0:name>
        <ns0:type>Environment → Observations</ns0:type>
        <ns0:notation>observe</ns0:notation>
        <ns0:description>collects data</ns0:description>
      </ns0:component>
      <ns0:component>
        <ns0:name>learn</ns0:name>
        <ns0:type>Observations → Model</ns0:type>
        <ns0:notation>learn</ns0:notation>
        <ns0:description>trains or updates model</ns0:description>
      </ns0:component>
      <ns0:component>
        <ns0:name>update</ns0:name>
        <ns0:type>Model → Policy</ns0:type>
        <ns0:notation>update</ns0:notation>
        <ns0:description>updates decision policy</ns0:description>
      </ns0:component>
      <ns0:component>
        <ns0:name>apply</ns0:name>
        <ns0:type>Policy → Actions</ns0:type>
        <ns0:notation>apply</ns0:notation>
        <ns0:description>applies learned policy</ns0:description>
      </ns0:component>
    </ns0:components>
  </ns0:definition>
  <ns0:type-definitions>
    <ns0:type-def>
      <ns0:name>Observations</ns0:name>
      <ns0:definition format="latex">Sequence⟨(State, Action, Reward)⟩</ns0:definition>
    </ns0:type-def>
    <ns0:type-def>
      <ns0:name>Model</ns0:name>
      <ns0:definition format="latex">Learned representation of environment</ns0:definition>
    </ns0:type-def>
    <ns0:type-def>
      <ns0:name>Policy</ns0:name>
      <ns0:definition format="latex">Decision-making strategy</ns0:definition>
    </ns0:type-def>
    <ns0:type-def>
      <ns0:name>Actions</ns0:name>
      <ns0:definition format="latex">Commands applied to environment</ns0:definition>
    </ns0:type-def>
  </ns0:type-definitions>
  <ns0:properties>
    <ns0:property id="P.F3.1.1">
      <ns0:name>Continuous Improvement</ns0:name>
      <ns0:formal-spec format="latex">∀t: accuracy(model_t+1) ≥ accuracy(model_t) ∨ explore(new_strategy)</ns0:formal-spec>
    </ns0:property>
    <ns0:property id="P.F3.1.2">
      <ns0:name>Feedback Integration</ns0:name>
      <ns0:formal-spec format="latex">∀observation ∈ Observations: observation influences future policy</ns0:formal-spec>
    </ns0:property>
    <ns0:property id="P.F3.1.3">
      <ns0:name>Convergence</ns0:name>
      <ns0:formal-spec format="latex">lim_{t→∞} improvement(model_t) → 0
Eventually reaches optimal or near-optimal</ns0:formal-spec>
    </ns0:property>
  </ns0:properties>
  <ns0:operations>
    <ns0:operation>
      <ns0:name>Execute Loop</ns0:name>
      <ns0:signature>loop(environment: Environment) → Effect</ns0:signature>
      <ns0:formal-definition format="latex">```
   loop(environment: Environment) → Effect
   = observations := []
     model := initialize_model()
     while running:
       obs := observe(environment)
       observations := observations + [obs]
       if should_update(observations):
         model := learn(observations)
         policy := update(model)
         actions := apply(policy, environment)</ns0:formal-definition>
    </ns0:operation>
    <ns0:operation>
      <ns0:name>Learn</ns0:name>
      <ns0:signature>learn(observations: Observations) → Model</ns0:signature>
      <ns0:formal-definition format="latex">```
   learn(observations: Observations) → Model
   = features := extract_features(observations)
     model := train(features, current_model)
     validate(model, validation_set)
     return model</ns0:formal-definition>
    </ns0:operation>
    <ns0:operation>
      <ns0:name>Apply</ns0:name>
      <ns0:signature>apply(policy: Policy, env: Environment) → Actions</ns0:signature>
      <ns0:formal-definition format="latex">```
   apply(policy: Policy, env: Environment) → Actions
   = state := env.current_state()
     action := policy.select_action(state)
     env.execute(action)
     return action</ns0:formal-definition>
    </ns0:operation>
  </ns0:operations>
  <ns0:manifestations>
    <ns0:manifestation>
      <ns0:name>Reinforcement learning systems</ns0:name>
    </ns0:manifestation>
    <ns0:manifestation>
      <ns0:name>Recommender systems</ns0:name>
    </ns0:manifestation>
    <ns0:manifestation>
      <ns0:name>Adaptive user interfaces</ns0:name>
    </ns0:manifestation>
    <ns0:manifestation>
      <ns0:name>Auto-tuning systems</ns0:name>
    </ns0:manifestation>
    <ns0:manifestation>
      <ns0:name>Online learning algorithms</ns0:name>
    </ns0:manifestation>
  </ns0:manifestations>
</ns0:pattern>